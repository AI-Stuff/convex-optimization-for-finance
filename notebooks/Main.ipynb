{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interactive, interact\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import cvxpy as cvx\n",
    "import ipyvolume.pylab as p3\n",
    "\n",
    "import bokeh.plotting as bp\n",
    "from bokeh.models import HoverTool\n",
    "\n",
    "bp.output_notebook()\n",
    "\n",
    "import itertools\n",
    "\"\"\n",
    "import holoviews as hv\n",
    "hv.extension('bokeh')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rc('figure', figsize=(14, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def surface3d(f, xs, ys=None, show=True, logcolor=False, key=None):\n",
    "    if ys is None:\n",
    "        ys = xs\n",
    "    xs, ys = np.meshgrid(xs, ys)\n",
    "    zs = f(xs, ys)\n",
    "    \n",
    "    if logcolor:\n",
    "        znorm = np.log1p(zs - zs.min())\n",
    "    else:\n",
    "        znorm = zs\n",
    "    znorm /= znorm.max()\n",
    "    color = mpl.cm.plasma(znorm)[..., 0:3]\n",
    "    \n",
    "    fig = p3.figure(key=key)\n",
    "    p3.plot_surface(xs, ys, zs, color=color)\n",
    "    \n",
    "    if show:\n",
    "        p3.show()\n",
    "        \n",
    "\n",
    "def isosurface3d(f, xs, ys=None, zs=None, show=True, key=None):\n",
    "    if ys is None:\n",
    "        ys = xs\n",
    "    if zs is none:\n",
    "        zs = xs\n",
    "        \n",
    "    xs, ys, zs = np.meshgrid(xs, ys, zs)\n",
    "    density = f(xs, ys, zs)\n",
    "        \n",
    "    fig = p3.figure(key=key)\n",
    "    \n",
    "    if show:\n",
    "        p3.show()\n",
    "\n",
    "def line2d(f, xs, fig=None, ax=None, **kwargs):\n",
    "    xs = np.array(xs)\n",
    "    if fig is None:\n",
    "        fig = plt.gcf()\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    ax.plot(xs, f(xs), **kwargs)\n",
    "    return fig, ax\n",
    "\n",
    "def scatter2d(f, xs, fig=None, ax=None):\n",
    "    xs = np.array(xs)\n",
    "    if fig is None:\n",
    "        fig = plt.gcf()\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    ax.scatter(xs, f(xs), **kwargs)\n",
    "    return fig, ax  \n",
    "        \n",
    "def scatter3d(xs, ys, zs, show=True, marker='sphere', color='red', key=None):\n",
    "    p3.scatter(xs, ys, zs, marker=marker, color=color)\n",
    "\n",
    "def plot_contours(f, x0, x1, levels=[1, 2, 3, 4], title=\"\"):\n",
    "    xx, yy = np.meshgrid(np.linspace(-2, 2, 50), np.linspace(-2, 2, 50))\n",
    "    z = f(xx, yy)\n",
    "    \n",
    "    line = interpolate(x0, x1)\n",
    "    curve = (hv.Curve((line[:, 0], line[:, 1]), label='x0 -> x1')\n",
    "             .options(color='red', line_width=3, line_dash='dashed'))\n",
    "    \n",
    "    scatter = (hv.Scatter(([x0[0], x1[0]], [x0[1], x1[1]]), extents=(-2, -2, 2, 2))\n",
    "               .options(color='red', size=10))\n",
    "    \n",
    "    contour = (hv.operation.contours(hv.Image(z, bounds=(-2, -2, 2, 2)), levels=levels)\n",
    "                .options(line_width=3))\n",
    "    \n",
    "    return (hv.Overlay([contour, scatter, curve],  label=title)\n",
    "            .options(height=450, width=700, legend_position='top_left', show_title=True))\n",
    "\n",
    "def plot_convex1d(f, x0, x1, title=\"\"):\n",
    "    # Prepare data\n",
    "    theta = np.linspace(0, 1, 50)\n",
    "    xs = x0 * theta + (x1 * (1 - theta))\n",
    "    ys = f(xs) \n",
    "    convex_bounds = f(x0) * theta + f(x1) * (1 - theta) \n",
    "    data = bp.ColumnDataSource({'x': xs, 'y': ys, 'theta': theta, 'bound': convex_bounds})\n",
    "    \n",
    "    # Plot figure\n",
    "    hover = HoverTool(mode='vline', names=['f'], \n",
    "                      tooltips=[(\"t\", \"@theta\"),\n",
    "                                (\"x\", \"@x\"),\n",
    "                                (\"f(x)\", \"@y\"), \n",
    "                                ('Convex Bound', \"@bound\")])\n",
    "    p = bp.figure(plot_width=700, plot_height=450, tools=[hover], title=title)\n",
    "    p.line('x', 'y', \n",
    "           source=data, line_width=5, name='f', legend='f(x0 * t + x1 * (1 - t))')\n",
    "    p.line('x', 'bound', \n",
    "           source=data, line_width=5, color='red', line_dash='dotted', legend='f(x0) * t + f(x1) * (1 - t)')                       \n",
    "    p.circle([x0, x1], [f(x0), f(x1)], color='red', size=20)\n",
    "    p.legend.location = 'top_left'\n",
    "    bp.show(p)\n",
    "    return p\n",
    "    \n",
    "def interpolate(x0, x1, samples=50):\n",
    "    x0 = np.array(x0)\n",
    "    x1 = np.array(x1)\n",
    "    theta = np.linspace(0, 1, samples)[:, None]\n",
    "    return theta * x0 + (1 - theta) * x1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "  <h1>Convex Optimization for Finance</h1>\n",
    "  <h3>Scott Sanderson</h3>\n",
    "  <h3>Email: ssanderson@quantopian.com, GitHub: [@ssanderson](https://github.com/ssanderson), Twitter: [@scottbsanderson](https://twitter.com/scottbsanderson)</h3>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Goals\n",
    "\n",
    "- Situate Convex Optimization within Broader Landscape\n",
    "- Build **Geometric** Intuition for Convex Functions and Convex Sets\n",
    "- Show Applications of Convex Optimization to Finance\n",
    "- Provide Resources for Further Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# Outline\n",
    "\n",
    "- **Optimization**\n",
    "- **Convex** Optimization\n",
    "- Convex Optimization **for Finance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Mathematical optimization is a family of techniques for finding a \"best\" value from a set of choices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A well-posed optimization problem has at least two parts:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A set $S$ of possible choices. Often called the **optimization domain**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- An scalar-valued **objective function** $f$ defined on $S$, to be **minimized** or **maximized**:\n",
    "  - **Loss/Cost Function** (minimization)\n",
    "  - **Utility Function** (maximization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We often also add a third component, a set of **constraints** on \"valid\" elements of $S$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We write optimization problems like this:\n",
    "\n",
    "\\begin{align}\n",
    "\\underset{x \\in S}{\\text{maximize}}&& f(x)&\\\\\n",
    "\\text{subject to}&& c_i(x)& = 1&&\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**In plain English:** *Find the value of $x$ in $S$ that maximizes $f(x)$ while satisfying all constraints $c_i$.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def rosenbrock(x, y):\n",
    "    \"\"\"The Rosenbrock function for a = 1, b = 7.5.\n",
    "    \n",
    "    See https://en.wikipedia.org/wiki/Rosenbrock_function.\n",
    "    \"\"\"\n",
    "    a = 1\n",
    "    b = 5 \n",
    "    return (a - x) ** 2 + b * (y - x ** 2) ** 2\n",
    "\n",
    "surface3d(rosenbrock, np.linspace(-1.5, 1.5), np.linspace(-0.5, 1.5), logcolor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "minimize(lambda p: rosenbrock(*p), x0=[0.0, 0.0], method='nelder-mead')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def minimize_traced(f, *args, **kwargs):\n",
    "    \"\"\"Call scipy.minimize, and store the points it asks us to evaluate.\n",
    "    \"\"\"\n",
    "    trace = []\n",
    "    \n",
    "    def traced_f(point):\n",
    "        trace.append(tuple(point))\n",
    "        return f(*point)\n",
    "\n",
    "    result = minimize(traced_f, *args, **kwargs)\n",
    "    return result, trace\n",
    "    \n",
    "result, trace = minimize_traced(rosenbrock, x0=[-1., 1.], method='nelder-mead')\n",
    "trace[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def show_optimization_trace(x0, y0, method):\n",
    "    func = rosenbrock; initial_point = [x0, y0]\n",
    "\n",
    "    result, trace = minimize_traced(func, x0=initial_point, method=method)\n",
    "    \n",
    "    xs, ys = zip(*trace)\n",
    "    zs = list(itertools.starmap(func, trace))\n",
    "    \n",
    "    surface3d(func, np.linspace(min(xs) * 1.1, max(xs) * 1.1), np.linspace(min(ys) * 1.1, max(ys) * 1.1), logcolor=True)\n",
    "    scatter3d(np.array(xs), np.array(ys), np.array(zs), color=np.linspace(0.1, 1, num= 2 * len(xs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "interact(show_optimization_trace, x0=-1.4, y0=1.0, method=['nelder-mead', 'powell']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import show_options\n",
    "\n",
    "show_options() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Convex Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "General purpose optimization is **hard**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In the most extreme cases, it's **impossible**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Under modest assumptions, it's *merely* computationally infeasible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Challenges\n",
    "\n",
    "- Number of candidates grows exponentially in the dimensionality of the search space.\n",
    "- Search algorithms can get \"trapped\" in local minima and/or saddle points.\n",
    "- Complex feasible regions are hard to navigate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can do much better if we can assume that our objective/constraints are \"well-behaved\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Convex Functions** and **Convex Constraints** are a particularly important class of well-behaved inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Convex Functions\n",
    "\n",
    "A function $f(x)$ is **convex** if:\n",
    "\n",
    "$$f(x_0t + x_1(1 - t)) \\leq f(x_0)t  + f(x_1)(1 - t)$$\n",
    "\n",
    "where\n",
    "\n",
    "$$t \\in [0, 1]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Intuition:**\n",
    "\n",
    "- Left-hand side is the point \"t-percent\" of the way between $x_0$ and $x_1$.\n",
    "- Right-hand side is the point \"t-percent\" of the way between $f(x_0)$ and $f(x_1)$.\n",
    "- Inequality says that $f$ is changing faster in the output space than the input space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot_convex1d(lambda x: x ** 2 + 2 * x - 1, -2, 2, \"Convex Function\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot_convex1d(lambda x: x ** 3 - 2 * x ** 2 - x, -5, 5, \"Non-Convex Function\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Multivariate Convexity\n",
    "\n",
    "Convexity generalizes naturally to arbitrary dimensions. \n",
    "\n",
    "The same inequality applies for $x \\in \\mathbb{R}^n$:\n",
    "\n",
    "$$f(x_0t  + x_1(1 - t)) \\leq f(x_0)t  + f(x_1)(1 - t) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def convex_func(x, y): \n",
    "    return x ** 2 + 3 * y ** 2\n",
    "\n",
    "plot_contours(convex_func, (-1, 0), (0, np.sqrt(3) / 3), np.linspace(0.5, 2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def nonconvex_func(x, y): \n",
    "    return x ** 2 + 4 * y ** 2 - 3 * np.sin(x ** 2 + y ** 2)\n",
    "\n",
    "plot_contours(nonconvex_func, (-0.5, 0.666), (0.5, 0.666), levels=np.linspace(0.1, 1, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Convex Sets\n",
    "\n",
    "Closely-related to **convex functions** is the concept of **convex sets**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let $C$ be a subset of $\\mathbb{R}^n$, and let $x_0, x_1 \\in C$.\n",
    "\n",
    "$C$ is convex iff:\n",
    "\n",
    "\\begin{align}\n",
    "t x_0 + (1 - t)x_1 \\in& C \\\\\n",
    "\\forall t \\in& [0, 1]\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**English:** If two points are in a convex set, every point on the line between them is also in the set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Useful Facts about Convexity\n",
    "\n",
    "- The intersection of two convex sets is also convex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Level surfaces of convex **functions** are the **boundaries** of **convex sets**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In 2 dimensions, a convex set doesn't intersect with **lines** tangent to its boundary\n",
    "- In 3 dimensions, a convex set doesn't intersect with **planes** tangent to its boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In general, an N-dimensional convex set doesn't intersect with its **supporting hyperplanes**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A scalar function is convex if it has positive second derivative.\n",
    "- In general, a twice-differentiable function is convex iff its Hessian is positive semi-definite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Convex Optimization\n",
    "\n",
    "Convexity is a very nice property for optimization.\n",
    "\n",
    "If the objective function $f$ is convex, and the **feasible region** satisfying all constraints is a convex set, then:\n",
    "\n",
    "- Local extrema are guaranteed to be global extrema.\n",
    "- There are efficient (polynomial-time) algorithms to find extrema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## CVX and Disciplined Convex Programming\n",
    "\n",
    "Most low-level solvers require you to specify a problem in \"canonical form\" as a collection of matrices. \n",
    "\n",
    "This can be hard to get right, and hard to debug if you get it wrong.\n",
    "\n",
    "Modelling languages solve this problem by translating from high-level expressions to low-level solver representations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## CVX and Disciplined Convex Programming\n",
    "\n",
    "[CVX](http://cvxr.com/cvx/) (MATLAB) and its siblings [CVXPY](https://github.com/cvxgrp/cvxpy) (Python) and [Convex.jl](https://github.com/JuliaOpt/Convex.jl) (Julia) implement a system called [Disciplined Convex Programming](http://dcp.stanford.edu/home).\n",
    "\n",
    "DCP allows you to build expressions out of a set of primitives with known curvature and sign. The modeling language translates from expressions into the canonical form of a target backend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Convex Optimization for Portfolio Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import cvxpy as cvx \n",
    "\n",
    "expected_returns = np.array([0.001, 0.002, 0.003, 0.004, 0.005])\n",
    "\n",
    "def maximize_returns(expected_returns):\n",
    "    \"\"\"Construct the portfolio that maximizes expected portfolio returns given\n",
    "    expected security-level returns.\n",
    "    \"\"\"\n",
    "    weights = cvx.Variable(len(expected_returns))\n",
    "    objective = cvx.Maximize(weights.T * expected_returns)\n",
    "    problem = cvx.Problem(objective, [cvx.sum_entries(cvx.abs(weights)) <= 1])\n",
    "    problem.solve()\n",
    "    return weights.value.round(3).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximize_returns(expected_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def markowitz_portfolio(means, cov, risk_aversion):\n",
    "    \"\"\"Generate the optimal fully-invested portfolio for a given risk/returns tradeoff.\n",
    "    \"\"\"\n",
    "    weights = cvx.Variable(len(means))\n",
    "    \n",
    "    expected_return = weights.T * means\n",
    "    expected_vol = cvx.quad_form(weights, cov)\n",
    "    \n",
    "    utility = expected_return - risk_aversion * expected_vol\n",
    "    objective = cvx.Maximize(utility)\n",
    "    \n",
    "    constraints = [\n",
    "        cvx.sum_entries(weights) == 1,  # fully-invested\n",
    "        weights >= 0,                   # long-only\n",
    "    ]\n",
    "    \n",
    "    problem = cvx.Problem(objective, constraints)\n",
    "    problem.solve()\n",
    "\n",
    "    return np.array(weights.value.flat).round(4), expected_return.value, expected_vol.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "expected_rets = np.array([0.001, 0.002, 0.003, 0.004, 0.005])\n",
    "cov = np.array([[0.02, 0. ,  0.  , 0.  , 0.  ],\n",
    "                [0.  , 0.02, 0.  , 0.  , 0.  ],\n",
    "                [0.  , 0.  , 0.02, 0.  , 0.  ],\n",
    "                [0.  , 0.  , 0.  , 0.02, 0.0 ],\n",
    "                [0.  , 0.  , 0.  , 0. , 0.02]])\n",
    "\n",
    "weights, rets, var = markowitz_portfolio(expected_rets, cov, 0.2)\n",
    "print(\"Weights:\", weights); print(\"Expected Return:\", rets); print(\"Expected Variance:\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import bokeh.plotting as bp\n",
    "\n",
    "def plot_efficient_frontier(means, cov, min_aversion=0, max_aversion=1, nsamples=25):\n",
    "    \"\"\"Plot the expected return and variance for different levels of risk aversion.\n",
    "    \"\"\"\n",
    "    samples = np.linspace(min_aversion, max_aversion, nsamples)\n",
    "    \n",
    "    portfolios = []\n",
    "    returns = []\n",
    "    stddevs = []\n",
    "    for aversion in samples:\n",
    "        portfolio, ret, var = markowitz_portfolio(means, cov, aversion)\n",
    "        portfolios.append(portfolio)\n",
    "        returns.append(ret)\n",
    "        stddevs.append(var)\n",
    "        \n",
    "    fig = bp.figure()\n",
    "    fig.scatter(stddevs, returns)\n",
    "    fig.xaxis.axis_label = 'Risk'\n",
    "    fig.yaxis.axis_label = 'Return'\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "bp.show(plot_efficient_frontier(expected_rets, cov))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example: Constraining Historical Downside Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "alphas = np.linspace(-2, 2, 8)\n",
    "rets = np.random.standard_t(df=10, size=(500, 8)) * 0.1\n",
    "pd.DataFrame(rets).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def maximize_alpha_constrain_downside(alphas, returns, percentile, max_loss):\n",
    "    weights = cvx.Variable(returns.shape[1])\n",
    "\n",
    "    # Number of worst-case return periods to sample.\n",
    "    nsamples = round(returns.shape[0] * percentile)\n",
    "\n",
    "    portfolio_rets = returns * weights\n",
    "    avg_worst_day = cvx.sum_smallest(portfolio_rets, nsamples) / nsamples\n",
    "    \n",
    "    objective = cvx.Maximize(weights.T * alphas)\n",
    "    constraints = [avg_worst_day >= max_loss]\n",
    "    \n",
    "    problem = cvx.Problem(objective, constraints)\n",
    "    problem.solve()\n",
    "  \n",
    "    return weights.value.round(4).ravel()\n",
    "    \n",
    "result = maximize_alpha_constrain_downside(alphas, rets, percentile=0.05, max_loss=-0.05)\n",
    "print(\"Portfolio:\", result)\n",
    "\n",
    "portfolio_rets = rets.dot(result)\n",
    "worst_days = portfolio_rets[portfolio_rets <= np.percentile(portfolio_rets, 5)]\n",
    "print(\"Average Bad Day:\", worst_days.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Python has lots of great tools for optimization.\n",
    "  - `scipy.optimize`\n",
    "  - `cvxpy`\n",
    "  - ... lots of other tools not covered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Convex functions \"curve upward\" when traversing lines between points.\n",
    "- Convex sets always contain lines between points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Convex optimization can be used to **efficiently** solve a wide array of interesting problems.\n",
    "- High-level modeling tools like `cvxpy` or `quantopian.optimize` mean that you don't need to be an expert to productively use convex solvers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Questions?\n",
    "\n",
    "- **GitHub:** https://github.com/ssanderson\n",
    "- **Twitter:** @scottbsanderson\n",
    "- **Email:** scott@quantopian.com"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
